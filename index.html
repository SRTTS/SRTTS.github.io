<h1 style="text-align: center;"><span style="color: #0000ff;"><strong>Samsung Research TTS</strong></span></h1>
<h2 style="text-align: center;">Publications</h2>
<article><header>
<h3 style="text-align: center;"><strong><a href="https://bunchedlpcnet.github.io/">Bunched LPCNet : Vocoder for Low-cost Neural Text-To-Speech Systems</a></strong></h3>
<p style="text-align: center;">Authors; *Ravichander Vipperla, *Sangjun Park, *Kihyun Choo, Samin Ishtiaq, Kyoungbo Min,<br>Sourav Bhattacharya, Abhinav Mehrotra, Alberto Gil C. P. Ramos, Nicholas D. Lane</p>
<p style="text-align: center;"><strong><span style="color: #339966;">Interspeech 2020</span></strong></p>
<h3 style="text-align: center;"><strong><a href="/bunchedLPCNet2/">Bunched LPCNet2 : Efficient Neural Vocoders Covering Devices from Cloud to Edge</a></strong></h3>
<p style="text-align: center;">Authors; Sangjun Park, Kihyun Choo, Joohyung Lee, Anton V. Porov, Konstantin Osipov, June Sing Sung</p>
<p style="text-align: center;"><strong><span style="color: #339966;">Interspeech 2022</span></strong></p>
<h3 style="text-align: center;"><strong><a href="/IntoTTS/">Into-TTS : Intonation Template Based Prosody Control System</a></strong></h3>
<p style="text-align: center;">Authors; Jihwan Lee, Joun Yeop Lee, Heejin Choi, Seongkyu Mun, Sangjun Park, Jae-Sung Bae, Chanwoo Kim</p>
<p style="text-align: center;"><strong><span style="color: #339966;">Preprint arXiv</span></strong></p>
<h3 style="text-align: center;"><strong><a href="/tc-zstts/">Hierarchical Timbre-Cadence Speaker Encoder for Zero-shot Speech Synthesis</a></strong></h3>
<p style="text-align: center;">Authors; Joun Yeop Lee, Jae-Sung Bae, Seongkyu Mun, Jihwan Lee, Ji-Hyun Lee, Hoon-Young Cho, Chanwoo Kim</p>
<p style="text-align: center;"><strong><span style="color: #339966;">Interspeech 2023</span></strong></p>
<h3 style="text-align: center;"><strong><a href="/mels-tts/">MELS-TTS : Multi-Emotion Multi-Lingual Multi-Speaker Text-to-Speech System via Disentangled Style Tokens</a></strong></h3>
<p style="text-align: center;">Authors; Heejin Choi, Jae-Sung Bae, Joun Yeop Lee, Seongkyu Mun, Jihwan Lee, Hoon-Young Cho, Chanwoo Kim</p>
<p style="text-align: center;"><strong><span style="color: #339966;">ICASSP 2024</span></strong></p>
<h3 style="text-align: center;"><strong><a href="/latent-filling/">Latent Filling: Latent Space Data Augmentation for Zero-shot Speech Synthesis</a></strong></h3>
<p style="text-align: center;">Authors; Jae-Sung Bae, Joun Yeop Lee, Ji-Hyun Lee, Seongkyu Mun, Taehwa Kang, Hoon-Young Cho, Chanwoo Kim</p>
<p style="text-align: center;"><strong><span style="color: #339966;">ICASSP 2024</span></strong></p>
<h3 style="text-align: center;"><strong><a href="/interpreting-speaking/">High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model</a></strong></h3>
<p style="text-align: center;">Authors; Joun Yeop Lee, Myeonghun Jeong, Minchan Kim, Ji-Hyun Lee, Hoon-Young Cho, Nam Soo Kim</p>
<p style="text-align: center;"><strong><span style="color: #339966;">Interspeech 2024</span></strong></p>
  <h3 style="text-align: center;"><strong><a href="/mamba-depthwise/">Efficient Streaming TTS Acoustic Model with Depthwise RVQ Decoding Strategies in a Mamba Framework</a></strong></h3>
<p style="text-align: center;">Authors; Joun Yeop Lee, Sangjun Park, Byoung Jin Choi, Ji-Hyun Lee, Min-Kyung Kim, Hoon-Young Cho</p>
<p style="text-align: center;"><strong><span style="color: #339966;">Interspeech 2025</span></strong></p>
</header></article>
